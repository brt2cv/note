{"root":{"data":{"text":"sklearn-机器学习"},"children":[{"data":{"text":"算法分类","expandState":"expand","hyperlink":"https://www.cnblogs.com/brt2/p/13697564.html","hyperlinkTitle":"","layout":null},"children":[{"data":{"text":"回归算法","layout":null},"children":[{"data":{"text":"线性回归","layout":null},"children":[{"data":{"text":"多元线性回归：sklearn.linear_model.LinearRegression","layout":null}},{"data":{"text":"多项式回归：sklearn.preprocessing.PolynomialFeatures","layout":null}},{"data":{"text":"过拟合问题","expandState":"expand","layout":null},"children":[{"data":{"text":"丢弃一些对我们最终预测结果影响不大的特征（PCA）","layout":null}},{"data":{"text":"正则化线性回归（增加损失函数）","expandState":"expand","layout":null},"children":[{"data":{"text":"岭回归（Ridge Regression）","note":"代价函数采用L2正则化","layout":null}},{"data":{"text":"LASSO（引入的是L1范数惩罚项）","note":"计算量Lasso回归将远远小于岭回归","layout":null}}]}]},{"data":{"text":"应用案例"},"children":[{"data":{"text":"房价预测"},"children":[{"data":{"text":"Kaggle"}}]}]}]},{"data":{"text":"逻辑回归","layout":null},"children":[{"data":{"text":"用于解决分类为题","font-weight":"bold","layout":null}}]}]},{"data":{"text":"分类算法","layout":null,"expandState":"expand"},"children":[{"data":{"text":"k近邻（KNN）","layout":null},"children":[{"data":{"text":"普通的k-均值算法"}},{"data":{"text":"带权重的k-均值算法"}},{"data":{"text":"指定半径的k-均值算法: KNeighborsClassifier"}}]},{"data":{"text":"贝叶斯","layout":null},"children":[{"data":{"text":"GaussianNB实现了高斯分布的朴素贝叶斯算法"}},{"data":{"text":"MultinomialNB实现了多项式分布的朴素贝叶斯算法"}},{"data":{"text":"BernoulliNB实现了伯努利分布的朴素贝叶斯算法"}}]},{"data":{"text":"支持向量机（SVM）","layout":null}},{"data":{"text":"决策树, Decision Tree","font-weight":"bold","layout":null,"expandState":"collapse"},"children":[{"data":{"text":"算法","expandState":"expand"},"children":[{"data":{"text":"理论","expandState":"expand"},"children":[{"data":{"text":"信息熵","note":"值越大，表示越 “不纯”"},"children":[{"data":{"text":"Gini不纯度"}},{"data":{"text":"Entropy"}}]},{"data":{"text":"信息增益（纯度差）"}},{"data":{"text":"停止条件：避免过拟合","note":"一种最直观的方式是当每个子节点只有一种类型的记录时停止，但是这样往往会使得树的节点过多，导致过拟合问题（`Overfitting`）。\n\n另一种可行的方法是当前节点中的记录数低于一个最小的阀值，那么就停止分割，将max(P(i))对应的分类作为当前叶节点的分类。"}},{"data":{"text":"树剪枝：避免对噪音/孤立点拟合","expandState":"expand","note":"在决策树构造时，由于训练数据中的噪音或孤立点，许多分枝反映的是训练数据中的异常，使用这样的判定树对类别未知的数据进行分类，分类的准确性不高"},"children":[{"data":{"text":"预剪枝","progress":null,"note":"实践证明这中策略无法得到较好的结果"},"children":[{"data":{"text":"在构建决策树的过程时，提前停止"},"children":[{"data":{"text":"max_depth"}},{"data":{"text":"min_impurity_split"}}]},{"data":{"text":"会将切分节点的条件设置的很苛刻，导致决策树很短小；\n结果就是决策树无法达到最优"}}]},{"data":{"text":"后剪枝","progress":null,"note":"后置裁剪有个问题就是计算效率，有些节点计算后就被裁剪了，导致有点浪费。"},"children":[{"data":{"text":"决策树构建好后，然后才开始裁剪"}},{"data":{"text":"1）用单一叶节点代替整个子树，叶节点的分类采用子树中最主要的分类"}},{"data":{"text":"2）将一个字数完全替代另外一颗子树"}},{"data":{"text":"scikit-learn不支持后剪枝","priority":null,"font-weight":"bold"}}]}]}]},{"data":{"text":"ID3算法\n决策树会选择最大化*信息增益*来对结点进行划分","expandState":"expand","layout":null},"children":[{"data":{"text":"用信息增益选择属性时偏向于选择分枝比较多的属性值，即取值多的属性"}},{"data":{"text":"不能处理连续属性"}}]},{"data":{"text":"C4.5算法","layout":null,"expandState":"expand"},"children":[{"data":{"text":"对于ID3算法的重要改进是，\n使用*信息增益率*来选择节点属性","note":"注意：增益率准则对可取值数目较少的属性有所偏好，因此C4.5算法并不是直接选择增益率最大的属性作为分支标准，而是先从候选属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。"}},{"data":{"text":"C4.5算法可以克服ID3存在的不足"}}]},{"data":{"text":"CART算法\nCART用基尼(Gini不纯度)系数最小化准则来进行特征选择","layout":null},"children":[{"data":{"text":"二分(Binary Split)：在每次判断过程中，都是对样本数据进行二分"}},{"data":{"text":"单变量分割(Split Based on One Variable)：每次最优划分都是针对单个变量"}},{"data":{"text":"剪枝策略：CART算法的关键点，也是整个Tree-Based算法的关键步骤","font-weight":"bold"}}]}]},{"data":{"text":"适用领域"},"children":[{"data":{"text":"数据要求","expandState":"expand"},"children":[{"data":{"text":"属性应该只有少量几个值\n例如酱汁=红色、白色或粉红色"}},{"data":{"text":"实例用一组属性值表示\n例如实例=意粉和肉丸"}},{"data":{"text":"目标函数只有少量的几个离散值。\n在意大利面食的例子中，值为Yes和No"}}]},{"data":{"text":"适用于小规模数据集","font-weight":"bold"}},{"data":{"text":"缺点"},"children":[{"data":{"text":"处理连续变量不好，更适合处理离散数据"}},{"data":{"text":"不能处理大量数据"}}]}]},{"data":{"text":"案例"},"children":[{"data":{"text":"决策树广泛应用于医疗行业","note":"医疗应用中，属性对应于可见的症状或患者的描述（皮肤颜色=黄色、鼻子=流涕、出现头痛）或测试结果（体温升高、血压或血糖水平高、心脏酶异常）医疗应用中的目标函数可能表明存在某种疾病或病症：病人出现花粉症、肝炎或最近修复的心脏瓣膜有点问题。"}},{"data":{"text":"金融领域"},"children":[{"data":{"text":"信用卡价值决定"}},{"data":{"text":"房地产投资的有利条件"}}]}]},{"data":{"text":"scikit-learn决策树采用CART算法"},"children":[{"data":{"text":"DecisionTreeClassifier"}},{"data":{"text":"DecisionTreeRegressor"}}]}]},{"data":{"text":"随机森林","layout":null,"hyperlink":"https://easyai.tech/ai-definition/random-forest/","hyperlinkTitle":""}}]},{"data":{"text":"聚类，无监督学习算法","layout":null},"children":[{"data":{"text":"聚类（k-Means）","layout":null},"children":[{"data":{"text":"sklearn.cluster.KMeans"}}]},{"data":{"text":"谱聚类","layout":null}},{"data":{"text":"均值漂移","layout":null}}]},{"data":{"text":"降维","layout":null},"children":[{"data":{"text":"PCA","layout":null}},{"data":{"text":"特征选择","layout":null}},{"data":{"text":"非负矩阵分解","layout":null}}]}]},{"data":{"text":"概念"},"children":[{"data":{"text":"优化器","layout":null}},{"data":{"text":"反向传播网络（BPN）"}},{"data":{"text":"模型参数选择工具包：GridSearchCV","note":"from sklearn.model_selection import GridSearchCV","hyperlink":"https://blog.csdn.net/u011436316/article/details/92141250","hyperlinkTitle":""}},{"data":{"text":"过拟合"},"children":[{"data":{"text":"欠拟合"},"children":[{"data":{"text":"增加有价值的特征"}},{"data":{"text":"增加多项式特征"}}]},{"data":{"text":"过拟合"},"children":[{"data":{"text":"获取更多的训练数据"}},{"data":{"text":"减少输入的特征数量","note":"比如，针对书写识别系统，原来使用200×200的图片，总共40000个特征。优化后，我们可以把图片等比例缩小为10×10的图片，总共100个特征。这样可以大大减少模型的计算量，同时也减少模型的复杂度，改善过拟合问题。"}},{"data":{"text":"正则化"},"children":[{"data":{"text":"L1范数正则项"}},{"data":{"text":"L2范数正则项"}}]}]}]}]},{"data":{"text":"sklearn-API","layout":null},"children":[{"data":{"text":"基本流程","hyperlink":"https://www.cnblogs.com/brt2/p/15531778.html#12-%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B","hyperlinkTitle":"","layout":null},"children":[{"data":{"text":"划分训练集与测试集","note":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = split(X, y, random_state=0)","layout":null}},{"data":{"text":"数据预处理","expandState":"expand","layout":null},"children":[{"data":{"text":"标准化","note":"from sklearn.preprocessing import StandardScaler","layout":null}},{"data":{"text":"归一化","note":"from sklearn.preprocessing import Normalizer","layout":null}},{"data":{"text":"二值化","note":"from sklearn.preprocessing import Binarizer","layout":null}}]},{"data":{"text":"模型选择与构建","layout":null}},{"data":{"text":"模型训练","note":"fit(X_train, y_train)","layout":null}},{"data":{"text":"模型测试 & 评估","note":"from sklearn.metrics import accuracy_score\n\nYpred = clf.predict(Xtest)\naccuracy_score(Ytest, Ypred)\n\n或： `estimator.score(x_test, y_test)`","layout":null},"children":[{"data":{"text":"predict(): 返回分类最高的类别","layout":null}},{"data":{"text":"predict_proba(): 返回各个类型的可能性","layout":null}}]},{"data":{"text":"模型保存与加载","note":"from sklearn.externals import joblib\n\njoblib.dump(clf, 'digits_svm.pk1')\nclf = joblib.load('digits_svm.pk1')","layout":null}}]},{"data":{"text":"Pipeline","layout":null},"children":[{"data":{"text":"batch, 批次：取值32-100"}}]}]}]},"template":"default","theme":"fresh-blue","version":"1.4.43"}